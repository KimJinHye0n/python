{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_II3ih8wEnZY"
   },
   "source": [
    "# 전체 코드 실행 후 테스트 코드를 실행해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wt9mHkFWviXp",
    "outputId": "c6bdc7da-29a6-4b97-9d21-a3624d5dbcbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath:  /usr/local/lib/python3.6/dist-packages\n",
      "classpath:  /usr/local/lib/python3.6/dist-packages/rhinoMorph/lib/rhino.jar\n",
      "RHINO started!\n",
      "[██████████████████████████████████████████████████]\n",
      "[██████████████████████████████████████████████████]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import gluonnlp as nlp\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rhinoMorph\n",
    "# Loading en_vocab_list\n",
    "with open(\"/content/drive/MyDrive/Ai_test/1000common_list_en.txt\", \"r\") as file:\n",
    "    lines = file.read().split(',')\n",
    "# Loading Rihno\n",
    "rn = rhinoMorph.startRhino()\n",
    "# Setting Device\n",
    "device = torch.device(\"cpu\")\n",
    "# Loading Kobert Vocab\n",
    "_, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UEJmZdQMxHtF"
   },
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, bert, hidden_size = 768, num_classes=9, dr_rate=None, params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XF7pz9rvvcgD",
    "outputId": "c5c8b76e-389e-4ca0-e8de-e06736319243"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n"
     ]
    }
   ],
   "source": [
    "# Loading Model\n",
    "model = torch.load('/content/drive/MyDrive/Ai_test/model_KoBert_RhinoDataRefine.pt', map_location=device)\n",
    "model.eval()\n",
    "print('Model Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ByT0d_2_GgwF"
   },
   "outputs": [],
   "source": [
    "def del_unimportant_n(sentence, lines, rn):\n",
    "  sentence = sentence.replace('\\r','')\n",
    "  sentence = sentence.replace('\\n','')\n",
    "  sentence = sentence.replace('\\([^)]*\\)', '')\n",
    "  sentence = str.upper(sentence)\n",
    "  sentence = sentence.replace(\"[^가-힣A-Z0-9=%\\. ]\",\"\")\n",
    "  del_dic = {}\n",
    "  n_list = rhinoMorph.onlyMorph_list(rn, sentence, pos=['SL'])\n",
    "  for n in n_list:\n",
    "    if len(n)>1:\n",
    "      if n not in lines:\n",
    "        del_dic[n] = ''\n",
    "  if len(del_dic)!=0:\n",
    "    sentence = pd.Series(sentence)\n",
    "    new_sentence = sentence.replace(del_dic, regex=True)\n",
    "  else:\n",
    "    new_sentence = pd.Series(sentence)\n",
    "  new_sentence = new_sentence.replace({' +':' '}, regex=True)\n",
    "  return new_sentence[0]\n",
    "\n",
    "def BERT_change(sentence) :\n",
    "    sentence = del_unimportant_n(sentence, lines, rn)\n",
    "    tokenizer= nlp.data.BERTSPTokenizer(get_tokenizer(), vocab, lower=False)\n",
    "    transform = nlp.data.BERTSentenceTransform(tokenizer, max_seq_length = 128, pad = True, pair = False)\n",
    "    sentence_val = transform([sentence])\n",
    "    inputs = torch.tensor(sentence_val[0], dtype=torch.long)\n",
    "    inputs = inputs.unsqueeze(0)\n",
    "    lens = torch.tensor(sentence_val[1])\n",
    "    lens = lens.unsqueeze(0)\n",
    "    masks = torch.tensor(sentence_val[2])\n",
    "    return inputs, lens, masks\n",
    "\n",
    "def test_sentences(sentences):\n",
    "    inputs, lens, masks = BERT_change(sentences)\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_lens = lens.to(device)\n",
    "    b_masks = masks.to(device)\n",
    "    with torch.no_grad():     \n",
    "        outputs = model(b_input_ids, valid_length = b_lens, segment_ids = b_masks)\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    tagging = np.argmax(logits)\n",
    "    dicts_data = {0 : '가설 설정', 1 : '기술 정의', 2 : '대상 데이터', 3 : '데이터처리',\n",
    "                  4 : '문제 정의', 5 : '성능/효과', 6 : '이론/모형', 7 : '제안 방법', 8 : '후속연구'}\n",
    "    tagging = dicts_data[tagging]\n",
    "    return tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORJPpzGhVgYN"
   },
   "source": [
    "# 테스트 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xZg_8dUjlf3X",
    "outputId": "0893f84b-74e9-47d3-85fe-7364f6b7ab2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일명을 입력하세요 (xlsx 파일)\n",
      "test\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "--------------------\n",
      "가설 설정 : 80.0%\n",
      "--------------------\n",
      "기술 정의 : 100.0%\n",
      "--------------------\n",
      "대상 데이터 : 80.0%\n",
      "--------------------\n",
      "데이터처리 : 27.27%\n",
      "--------------------\n",
      "문제 정의 : 80.0%\n",
      "--------------------\n",
      "성능/효과 : 90.91%\n",
      "--------------------\n",
      "이론/모형 : 70.0%\n",
      "--------------------\n",
      "제안 방법 : 81.82%\n",
      "--------------------\n",
      "후속연구 : 100.0%\n",
      "--------------------\n",
      "종합 : 80.77%\n"
     ]
    }
   ],
   "source": [
    "print(\"파일명을 입력하세요 (xlsx 파일)\")\n",
    "x = input()\n",
    "data_xlsx = pd.read_excel((\"/content/drive/MyDrive/Ai_test/\"+ x + \".xlsx\"))\n",
    "data_xlsx['결과'] = 0\n",
    "for i, j in enumerate(data_xlsx['문장']) :\n",
    "    data_xlsx.loc[i, '결과'] = test_sentences(j)\n",
    "count = 0\n",
    "for i in range(len(data_xlsx['문장'])):\n",
    "    if data_xlsx.loc[i, '태그'] == data_xlsx.loc[i, '결과'] :\n",
    "      count += 1\n",
    "print(\"-\"*20)\n",
    "for i in data_xlsx['태그'].unique():\n",
    "    x = data_xlsx[data_xlsx['태그'] == i]\n",
    "    y = x[x['결과'] == i]\n",
    "    print(\"{} : {}%\".format(i, round(len(y)/len(x)*100, 2)))\n",
    "    print(\"-\"*20)\n",
    "print(\"종합 : {}%\".format(round(count / len(data_xlsx['문장']) * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "uTEJDFY62UwB",
    "outputId": "1f4638d8-2444-4720-b12e-075505e34194"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>태그</th>\n",
       "      <th>문장</th>\n",
       "      <th>결과</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>가설 설정</td>\n",
       "      <td>커피찌꺼기의 성분에는 최 등 2)의 연구에서 밝힌바와 같이 섬유성분이 46.6-51...</td>\n",
       "      <td>가설 설정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>가설 설정</td>\n",
       "      <td>중화기를 통과하는 공기 유량이 0.3 L/min인 경우, 입자가 평형 대전량 분포를...</td>\n",
       "      <td>가설 설정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>가설 설정</td>\n",
       "      <td>그렇기 때문에 주거의 기능은 디지털 시대 에 발 맞추어 LED의 다양한 조명연출 장...</td>\n",
       "      <td>가설 설정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>가설 설정</td>\n",
       "      <td>이렇듯 상당한 부분의 소비전력을 조명전력으로 사용하고 있는 실정이며, 선진국으로 갈...</td>\n",
       "      <td>가설 설정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>가설 설정</td>\n",
       "      <td>온실가스 저감량 도출은 2022년을 기준으로 1,490MW의 태양광발전 의무량이 설...</td>\n",
       "      <td>가설 설정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>후속연구</td>\n",
       "      <td>하지만 다시 의예과 선발 체제로 전환되기로 한 점, 의학과 4년 교육과정의 개발이 ...</td>\n",
       "      <td>후속연구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>후속연구</td>\n",
       "      <td>본 연구에서는 20명의 거북목 증후군 환자들을 대상으로 하여 결과를 일반화하기에는 ...</td>\n",
       "      <td>후속연구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>후속연구</td>\n",
       "      <td>본 논문에서는 간단한 구현 방안에 대해서만 제안하고 상세 구현 방안은 추후 연구를 ...</td>\n",
       "      <td>후속연구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>후속연구</td>\n",
       "      <td>향후,도서추천 목록에 대한 정확한 만족도 조사를 위한 별도의 방법이 마련되어야 하며...</td>\n",
       "      <td>후속연구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>후속연구</td>\n",
       "      <td>아울러, 도서검색 후 도서 위치 안내하는데 사용될 실내측위 기술과 온라인서평에 활용...</td>\n",
       "      <td>후속연구</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        태그                                                 문장     결과\n",
       "0    가설 설정  커피찌꺼기의 성분에는 최 등 2)의 연구에서 밝힌바와 같이 섬유성분이 46.6-51...  가설 설정\n",
       "1    가설 설정  중화기를 통과하는 공기 유량이 0.3 L/min인 경우, 입자가 평형 대전량 분포를...  가설 설정\n",
       "2    가설 설정  그렇기 때문에 주거의 기능은 디지털 시대 에 발 맞추어 LED의 다양한 조명연출 장...  가설 설정\n",
       "3    가설 설정  이렇듯 상당한 부분의 소비전력을 조명전력으로 사용하고 있는 실정이며, 선진국으로 갈...  가설 설정\n",
       "4    가설 설정  온실가스 저감량 도출은 2022년을 기준으로 1,490MW의 태양광발전 의무량이 설...  가설 설정\n",
       "..     ...                                                ...    ...\n",
       "99    후속연구  하지만 다시 의예과 선발 체제로 전환되기로 한 점, 의학과 4년 교육과정의 개발이 ...   후속연구\n",
       "100   후속연구  본 연구에서는 20명의 거북목 증후군 환자들을 대상으로 하여 결과를 일반화하기에는 ...   후속연구\n",
       "101   후속연구  본 논문에서는 간단한 구현 방안에 대해서만 제안하고 상세 구현 방안은 추후 연구를 ...   후속연구\n",
       "102   후속연구  향후,도서추천 목록에 대한 정확한 만족도 조사를 위한 별도의 방법이 마련되어야 하며...   후속연구\n",
       "103   후속연구  아울러, 도서검색 후 도서 위치 안내하는데 사용될 실내측위 기술과 온라인서평에 활용...   후속연구\n",
       "\n",
       "[104 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check tagging Results\n",
    "data_xlsx"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ft_change_ex_Fin.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
