{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QALJGGoDJcE"
   },
   "source": [
    "# 전체 코드 실행 후 테스트 코드를 실행해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wt9mHkFWviXp",
    "outputId": "6afd8be2-1354-49b8-f532-7bd5a36f9c94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath:  /usr/local/lib/python3.6/dist-packages\n",
      "classpath:  /usr/local/lib/python3.6/dist-packages/rhinoMorph/lib/rhino.jar\n",
      "JVM is already started~\n",
      "RHINO started!\n",
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import gluonnlp as nlp\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rhinoMorph\n",
    "# Loading en_vocab_list\n",
    "with open(\"/content/drive/MyDrive/Ai_test/1000common_list_en.txt\", \"r\") as file:\n",
    "    lines = file.read().split(',')\n",
    "# Loading Rihno\n",
    "rn = rhinoMorph.startRhino()\n",
    "# Setting Device\n",
    "device = torch.device(\"cpu\")\n",
    "# Loading Kobert Vocab\n",
    "_, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEJmZdQMxHtF"
   },
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, bert, hidden_size = 768, num_classes=9, dr_rate=None, params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPIgYZlh_22I"
   },
   "outputs": [],
   "source": [
    "# Loading Model\n",
    "model = torch.load('/content/drive/MyDrive/Ai_test/model_KoBert_RhinoDataRefine.pt', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bPpe1COW7r5J"
   },
   "outputs": [],
   "source": [
    "def del_unimportant_n(sentence, lines, rn):\n",
    "  sentence = sentence.replace('\\r','')\n",
    "  sentence = sentence.replace('\\n','')\n",
    "  sentence = sentence.replace('\\([^)]*\\)', '')\n",
    "  sentence = str.upper(sentence)\n",
    "  sentence = sentence.replace(\"[^가-힣A-Z0-9=%\\. ]\",\"\")\n",
    "  del_dic = {}\n",
    "  n_list = rhinoMorph.onlyMorph_list(rn, sentence, pos=['SL'])\n",
    "  for n in n_list:\n",
    "    if len(n)>1:\n",
    "      if n not in lines:\n",
    "        del_dic[n] = ''\n",
    "  if len(del_dic)!=0:\n",
    "    sentence = pd.Series(sentence)\n",
    "    new_sentence = sentence.replace(del_dic, regex=True)\n",
    "  else:\n",
    "    new_sentence = pd.Series(sentence)\n",
    "  new_sentence = new_sentence.replace({' +':' '}, regex=True)\n",
    "  return new_sentence[0]\n",
    "\n",
    "def BERT_change(sentence) :\n",
    "    sentence = del_unimportant_n(sentence, lines, rn)\n",
    "    tokenizer= nlp.data.BERTSPTokenizer(get_tokenizer(), vocab, lower=False)\n",
    "    transform = nlp.data.BERTSentenceTransform(tokenizer, max_seq_length = 128, pad = True, pair = False)\n",
    "    sentence_val = transform([sentence])\n",
    "    inputs = torch.tensor(sentence_val[0], dtype=torch.long)\n",
    "    inputs = inputs.unsqueeze(0)\n",
    "    lens = torch.tensor(sentence_val[1])\n",
    "    lens = lens.unsqueeze(0)\n",
    "    masks = torch.tensor(sentence_val[2])\n",
    "    return inputs, lens, masks\n",
    "\n",
    "def test_sentences(sentences):\n",
    "    model.eval()\n",
    "    inputs, lens, masks = BERT_change(sentences)\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_lens = lens.to(device)\n",
    "    b_masks = masks.to(device)\n",
    "    with torch.no_grad():     \n",
    "        outputs = model(b_input_ids, valid_length = b_lens, segment_ids = b_masks)\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    tagging = np.argmax(logits)\n",
    "    dicts_data = {0 : '가설 설정', 1 : '기술 정의', 2 : '대상 데이터', 3 : '데이터처리',\n",
    "                  4 : '문제 정의', 5 : '성능/효과', 6 : '이론/모형', 7 : '제안 방법', 8 : '후속연구'}\n",
    "    tagging = dicts_data[tagging]\n",
    "    return tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RE2JhqL6phw"
   },
   "source": [
    "# 테스트코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xZg_8dUjlf3X",
    "outputId": "d7c69628-2022-46ec-cd56-06d768bcf2b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "태깅할 문장을 하나씩 입력하세요 (종료:0) : 본 연구에서는 상수도 직결형 스프링클러 시스템의 성능을 평가하기 위하여 실물 주택을 대상으로 화재실험을 수행하였다.\n",
      "using cached model\n",
      "문장 태깅 결과 : 제안방법\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "태깅할 문장을 하나씩 입력하세요 (종료:0) : 철킬레이트 촉매를 이용한 2가나 3가 철을 사용하여 황화수소를 제거하기 위해 철염의 농도를 달리하여 제거효율을 측정하여 보았다.\n",
      "using cached model\n",
      "문장 태깅 결과 : 제안방법\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "태깅할 문장을 하나씩 입력하세요 (종료:0) : 특히 질량 흐름식을 사용하여 불확도를 계산하고 농도에 대한 합성불확도를 구하였다.\n",
      "using cached model\n",
      "문장 태깅 결과 : 제안방법\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "태깅할 문장을 하나씩 입력하세요 (종료:0) : 먼저 모듈 부품에서의 VOCs 방출량을 확인하기 위해 ISO 12219-4 (Small chamber method)를 사용 하였다.\n",
      "using cached model\n",
      "문장 태깅 결과 : 데이터처리\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "태깅할 문장을 하나씩 입력하세요 (종료:0) : 0\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "  x = input(\"태깅할 문장을 하나씩 입력하세요 (종료:0) : \")\n",
    "  if x=='0':\n",
    "    break\n",
    "  print('문장 태깅 결과 :',test_sentences(x))\n",
    "  print('-'*170)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ft_change_Fin.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
